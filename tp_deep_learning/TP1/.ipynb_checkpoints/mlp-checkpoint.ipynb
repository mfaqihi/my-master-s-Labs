{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 : Perceptron multi-couches (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 accuracy train= 92.09666666666666 accuracy test= 92.31\n",
      "epoch  1 accuracy train= 94.73666666666666 accuracy test= 94.41000000000001\n",
      "epoch  2 accuracy train= 96.03666666666668 accuracy test= 95.47\n",
      "epoch  3 accuracy train= 96.74666666666667 accuracy test= 96.14\n",
      "epoch  4 accuracy train= 97.24333333333334 accuracy test= 96.6\n",
      "epoch  5 accuracy train= 97.61999999999999 accuracy test= 96.84\n",
      "epoch  6 accuracy train= 97.90166666666667 accuracy test= 97.0\n",
      "epoch  7 accuracy train= 98.11999999999999 accuracy test= 97.15\n",
      "epoch  8 accuracy train= 98.28833333333333 accuracy test= 97.3\n",
      "epoch  9 accuracy train= 98.455 accuracy test= 97.42\n",
      "epoch  10 accuracy train= 98.62166666666667 accuracy test= 97.49\n",
      "epoch  11 accuracy train= 98.79166666666667 accuracy test= 97.55\n",
      "epoch  12 accuracy train= 98.92333333333333 accuracy test= 97.65\n",
      "epoch  13 accuracy train= 99.05666666666667 accuracy test= 97.66\n",
      "epoch  14 accuracy train= 99.17 accuracy test= 97.67\n",
      "epoch  15 accuracy train= 99.265 accuracy test= 97.66\n",
      "epoch  16 accuracy train= 99.33999999999999 accuracy test= 97.69\n",
      "epoch  17 accuracy train= 99.43333333333332 accuracy test= 97.72\n",
      "epoch  18 accuracy train= 99.505 accuracy test= 97.75\n",
      "epoch  19 accuracy train= 99.55833333333334 accuracy test= 97.72\n",
      "epoch  20 accuracy train= 99.61166666666666 accuracy test= 97.72\n",
      "epoch  21 accuracy train= 99.65666666666667 accuracy test= 97.72999999999999\n",
      "epoch  22 accuracy train= 99.72 accuracy test= 97.76\n",
      "epoch  23 accuracy train= 99.75166666666667 accuracy test= 97.77\n",
      "epoch  24 accuracy train= 99.77833333333334 accuracy test= 97.8\n",
      "epoch  25 accuracy train= 99.81166666666667 accuracy test= 97.84\n",
      "epoch  26 accuracy train= 99.83833333333332 accuracy test= 97.87\n",
      "epoch  27 accuracy train= 99.855 accuracy test= 97.86\n",
      "epoch  28 accuracy train= 99.87 accuracy test= 97.86\n",
      "epoch  29 accuracy train= 99.88 accuracy test= 97.87\n",
      "epoch  30 accuracy train= 99.885 accuracy test= 97.87\n",
      "epoch  31 accuracy train= 99.90166666666667 accuracy test= 97.87\n",
      "epoch  32 accuracy train= 99.91166666666666 accuracy test= 97.88\n",
      "epoch  33 accuracy train= 99.91666666666667 accuracy test= 97.86\n",
      "epoch  34 accuracy train= 99.93166666666666 accuracy test= 97.85000000000001\n",
      "epoch  35 accuracy train= 99.93666666666667 accuracy test= 97.83\n",
      "epoch  36 accuracy train= 99.95 accuracy test= 97.81\n",
      "epoch  37 accuracy train= 99.96166666666667 accuracy test= 97.85000000000001\n",
      "epoch  38 accuracy train= 99.96833333333333 accuracy test= 97.86\n",
      "epoch  39 accuracy train= 99.97 accuracy test= 97.89\n",
      "epoch  40 accuracy train= 99.97333333333333 accuracy test= 97.88\n",
      "epoch  41 accuracy train= 99.97666666666667 accuracy test= 97.88\n",
      "epoch  42 accuracy train= 99.98 accuracy test= 97.88\n",
      "epoch  43 accuracy train= 99.98333333333333 accuracy test= 97.87\n",
      "epoch  44 accuracy train= 99.98333333333333 accuracy test= 97.89999999999999\n",
      "epoch  45 accuracy train= 99.99166666666667 accuracy test= 97.91\n",
      "epoch  46 accuracy train= 99.99166666666667 accuracy test= 97.88\n",
      "epoch  47 accuracy train= 99.99166666666667 accuracy test= 97.87\n",
      "epoch  48 accuracy train= 99.995 accuracy test= 97.87\n",
      "epoch  49 accuracy train= 99.995 accuracy test= 97.87\n",
      "epoch  50 accuracy train= 99.995 accuracy test= 97.88\n",
      "epoch  51 accuracy train= 99.995 accuracy test= 97.91\n",
      "epoch  52 accuracy train= 99.995 accuracy test= 97.91\n",
      "epoch  53 accuracy train= 99.99666666666667 accuracy test= 97.91\n",
      "epoch  54 accuracy train= 99.99833333333333 accuracy test= 97.91\n",
      "epoch  55 accuracy train= 99.99833333333333 accuracy test= 97.91\n",
      "epoch  56 accuracy train= 99.99833333333333 accuracy test= 97.92\n",
      "epoch  57 accuracy train= 99.99833333333333 accuracy test= 97.95\n",
      "epoch  58 accuracy train= 100.0 accuracy test= 97.96000000000001\n",
      "epoch  59 accuracy train= 100.0 accuracy test= 97.97\n",
      "epoch  60 accuracy train= 100.0 accuracy test= 97.96000000000001\n",
      "epoch  61 accuracy train= 100.0 accuracy test= 97.97\n",
      "epoch  62 accuracy train= 100.0 accuracy test= 97.97\n",
      "epoch  63 accuracy train= 100.0 accuracy test= 97.96000000000001\n",
      "epoch  64 accuracy train= 100.0 accuracy test= 97.97\n",
      "epoch  65 accuracy train= 100.0 accuracy test= 97.97\n",
      "epoch  66 accuracy train= 100.0 accuracy test= 97.96000000000001\n",
      "epoch  67 accuracy train= 100.0 accuracy test= 97.97\n",
      "epoch  68 accuracy train= 100.0 accuracy test= 97.97\n",
      "epoch  69 accuracy train= 100.0 accuracy test= 97.96000000000001\n",
      "epoch  70 accuracy train= 100.0 accuracy test= 97.97\n",
      "epoch  71 accuracy train= 100.0 accuracy test= 97.97\n",
      "epoch  72 accuracy train= 100.0 accuracy test= 97.98\n",
      "epoch  73 accuracy train= 100.0 accuracy test= 97.99\n",
      "epoch  74 accuracy train= 100.0 accuracy test= 97.99\n",
      "epoch  75 accuracy train= 100.0 accuracy test= 97.99\n",
      "epoch  76 accuracy train= 100.0 accuracy test= 98.0\n",
      "epoch  77 accuracy train= 100.0 accuracy test= 97.99\n",
      "epoch  78 accuracy train= 100.0 accuracy test= 97.99\n",
      "epoch  79 accuracy train= 100.0 accuracy test= 97.98\n",
      "epoch  80 accuracy train= 100.0 accuracy test= 97.98\n",
      "epoch  81 accuracy train= 100.0 accuracy test= 97.99\n",
      "epoch  82 accuracy train= 100.0 accuracy test= 97.99\n",
      "epoch  83 accuracy train= 100.0 accuracy test= 97.99\n",
      "epoch  84 accuracy train= 100.0 accuracy test= 98.0\n",
      "epoch  85 accuracy train= 100.0 accuracy test= 98.00999999999999\n",
      "epoch  86 accuracy train= 100.0 accuracy test= 98.02\n",
      "epoch  87 accuracy train= 100.0 accuracy test= 98.02\n",
      "epoch  88 accuracy train= 100.0 accuracy test= 98.03\n",
      "epoch  89 accuracy train= 100.0 accuracy test= 98.03\n",
      "epoch  90 accuracy train= 100.0 accuracy test= 98.03\n",
      "epoch  91 accuracy train= 100.0 accuracy test= 98.03\n",
      "epoch  92 accuracy train= 100.0 accuracy test= 98.03\n",
      "epoch  93 accuracy train= 100.0 accuracy test= 98.03\n",
      "epoch  94 accuracy train= 100.0 accuracy test= 98.03\n",
      "epoch  95 accuracy train= 100.0 accuracy test= 98.03\n",
      "epoch  96 accuracy train= 100.0 accuracy test= 98.02\n",
      "epoch  97 accuracy train= 100.0 accuracy test= 98.03\n",
      "epoch  98 accuracy train= 100.0 accuracy test= 98.03\n",
      "epoch  99 accuracy train= 100.0 accuracy test= 98.03\n"
     ]
    }
   ],
   "source": [
    "K=10\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, K)\n",
    "Y_test = np_utils.to_categorical(y_test, K)\n",
    "d = X_train.shape[1]\n",
    "N = X_train.shape[0]\n",
    "L = 100\n",
    "sigma = 0.1\n",
    "Wh = np.random.randn(d,L) * sigma \n",
    "bh = np.zeros((1,L))\n",
    "Wy = np.random.randn(L,K) * sigma \n",
    "by = np.zeros((1,K))\n",
    "\n",
    "numEp = 100 # Number of epochs for gradient descent\n",
    "eta = 1.0 # Learning rate\n",
    "\n",
    "\n",
    "def softmax(X):\n",
    " # Input matrix X of size Nbxd - Output matrix of same size\n",
    " E = np.exp(X)\n",
    " return (E.T / np.sum(E,axis=1)).T\n",
    "\n",
    "def forward2(batch, Wh, bh, Wy, by):\n",
    "    #y_bar = np.dot(X_train,W);\n",
    "    u = np.dot(batch,Wh)+bh\n",
    "    h= 1/(1+np.exp(-1*u));\n",
    "    v = np.dot(h,Wy)+by\n",
    "    y_bar = softmax(v)\n",
    "    return y_bar, h;\n",
    "\n",
    "def accuracy2(Wh, bh, Wy, by, images, labels):\n",
    "  pred, Hn = forward2(images, Wh, bh, Wy, by )\n",
    "  return np.where( pred.argmax(axis=1) != labels.argmax(axis=1) , 0.,1.).mean()*100.0\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "nb_batches = int(float(N) / batch_size)\n",
    "\n",
    "for epoch in range(numEp):\n",
    "  for ex in range(nb_batches):\n",
    "     # FORWARD PASS : compute prediction with current params for examples in batch\n",
    "     batch = X_train[ex*batch_size:(ex+1)*batch_size,:]\n",
    "     y_batch = Y_train[ex*batch_size:(ex+1)*batch_size,:]\n",
    "     Y_bar, H = forward2(batch, Wh, bh, Wy, by);\n",
    "     Y_bar, H = forward2(batch, Wh, bh, Wy, by)\n",
    "     # BACKWARD PASS :\n",
    "     # 1) compute gradients for W and b\n",
    "     \n",
    "     gradv = Y_bar - y_batch\n",
    "        # gradWy = h^T * deltay - (LxN) * (NxK)\n",
    "     gradWy = 1.0/batch_size * np.matmul(np.transpose(H),gradv)\n",
    "     gradby = 1.0/batch_size * (gradv.sum(axis=0)).reshape((1,K))\n",
    "        # deltah   =dE / dh~ size (N,L)\n",
    "     deltah = np.matmul(gradv, np.transpose(Wy)) * (H* (1.0-H))\n",
    "    # gradWh = x^T * deltah - (dxN) * (NxL) = (dxL)\n",
    "     gradWh = 1.0/batch_size * np.matmul(np.transpose(X_train[ex*batch_size:(ex+1)*batch_size,:]),deltah)\n",
    "     gradbh = 1.0/batch_size * (deltah.sum(axis=0)).reshape((1,L)) \n",
    "     Wy = Wy - eta * gradWy\n",
    "     by = by - eta * gradby\n",
    "        \n",
    "     Wh = Wh - eta * gradWh\n",
    "     bh = bh - eta * gradbh\n",
    "    \n",
    "\n",
    "\n",
    "  print(\"epoch \", epoch, \"accuracy train=\",accuracy2(Wh, bh, Wy, by, X_train, Y_train), \"accuracy test=\",accuracy2(Wh, bh, Wy, by, X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
